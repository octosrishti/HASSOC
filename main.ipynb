{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import stemmer as hindi_stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "with open('final_stopwords.txt', encoding='utf-8') as f:\n",
    "    hindi_stopwords = f.readlines()\n",
    "    for i in range(len(hindi_stopwords)):\n",
    "        hindi_stopwords[i] = re.sub('\\n', '', hindi_stopwords[i])\n",
    "\n",
    "stopword = english_stopwords + hindi_stopwords\n",
    "english_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directories = []\n",
    "for i in glob(\"testdata/train/*/*/\"):\n",
    "    for j in glob(i+'*/'):\n",
    "        train_directories.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testdata/train\\\\German\\\\Anit-Vaxing\\\\1480483303253680129\\\\',\n",
       " 'testdata/train\\\\German\\\\Anti-Gender Language\\\\1383343760260567043\\\\',\n",
       " 'testdata/train\\\\German\\\\Antisemitismus\\\\1366314282665844739\\\\',\n",
       " 'testdata/train\\\\German\\\\Corona\\\\1467795022854639621\\\\',\n",
       " 'testdata/train\\\\German\\\\Corona\\\\1471440748797169668\\\\',\n",
       " 'testdata/train\\\\German\\\\corona measures\\\\1530446777681424385\\\\',\n",
       " 'testdata/train\\\\German\\\\Demonstrations\\\\1479045656933244932\\\\',\n",
       " 'testdata/train\\\\German\\\\Fatshaming\\\\1470487489982963722\\\\',\n",
       " 'testdata/train\\\\German\\\\Fatshaming\\\\1486792911492726785\\\\',\n",
       " 'testdata/train\\\\German\\\\Female Politician\\\\1467800206385324038\\\\',\n",
       " 'testdata/train\\\\German\\\\foreigners and crime\\\\1527188535593385984\\\\',\n",
       " 'testdata/train\\\\German\\\\hijab comedy\\\\1534472301269377024\\\\',\n",
       " 'testdata/train\\\\German\\\\LGBT\\\\1526193028309864448\\\\',\n",
       " 'testdata/train\\\\German\\\\male violence\\\\1534935096582721541\\\\',\n",
       " 'testdata/train\\\\German\\\\male violence\\\\1534939464199454720\\\\',\n",
       " 'testdata/train\\\\German\\\\Misogyny\\\\1484610443800887300\\\\',\n",
       " 'testdata/train\\\\German\\\\Rassismus\\\\1447562787249655809\\\\',\n",
       " 'testdata/train\\\\German\\\\transgender in sauna\\\\1534449943045361666\\\\',\n",
       " 'testdata/train\\\\German\\\\transgender in sauna\\\\1534635251816964097\\\\',\n",
       " 'testdata/train\\\\German\\\\transgender in sauna\\\\1534821168871505920\\\\',\n",
       " 'testdata/train\\\\German\\\\Transphoby\\\\1484671636708204545\\\\',\n",
       " 'testdata/train\\\\German\\\\Transphoby\\\\1484783200161390597\\\\',\n",
       " 'testdata/train\\\\German\\\\vaccination\\\\1388251454268399619\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\bullibai\\\\1477924941156605952\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\bullibai\\\\1478629984524587008\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\CAA\\\\1462412497084825600\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\CAA\\\\1471455877945180160\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\CAA\\\\1473004497513320450\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\CAA\\\\1473117582139932676\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\CAA\\\\1473123399765397506\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\CAA\\\\1473357974542307330\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cast\\\\1430916246644559876\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cast\\\\1443202065723916289\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cast\\\\1443243483301437445\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cast\\\\1469616932437381120\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1424709177906139138\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1425026689726246918\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1425056016459206656\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1425091814177001481\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1425111985922875402\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1438086487979954177\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1438709695166902279\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1438719575944622083\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1438761952679907334\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1438803587950256129\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1441383097119903752\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1442180719443210242\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1443986927938519041\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1444166274003570694\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1444167179415392258\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1444173510549524484\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1444185424394588162\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1444199065604943872\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1445331099333189638\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1445345549285134336\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1445378631958552576\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1445381930019696655\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1445409787542482954\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1447612071328112641\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1457629029599625223\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1457670233624305665\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1457717699690258441\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1462505338045747200\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1464851061882118147\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1464964256365875200\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1465002477548236808\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1467095423022080007\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1467109867160674312\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1467114029982175233\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1467128735782486016\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1467136027844235270\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1467146580595658757\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1468564789399982080\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1468808780888489986\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1468821276630269954\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1468871205067243526\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1469852663063846914\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1478014196952408064\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\celebrity_controversies\\\\1487753743185547267\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\common civil code\\\\1460287308939206662\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\common civil code\\\\1467825731182891008\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\covid\\\\1464310918389587974\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\covid\\\\1470391992970616843\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\covid\\\\1475708977178632194\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\covid\\\\1477924528495886336\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\covid\\\\1479177165539188736\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1242560043494621185\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1438820381075324932\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1438824588159459336\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1438856249530064896\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1438881267051814915\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1449434053422157825\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1450073335849635840\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1452288430549909516\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1452323201590124545\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\cricket\\\\1452844479124099082\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1445236478015991811\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1445281540280258562\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1445336020958859269\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1445338673185099779\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1448887019292168192\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1478660398710763522\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\farmer_protest\\\\1478711667454136320\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1214794148504457217\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1433450998702379024\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1433617324100120578\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1436173144591536129\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1448858962049314840\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1448902089204289537\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1456138648697462794\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1457394927130841093\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1467771110192140290\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1467789851411943430\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1467791638869135360\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1467814659717668866\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1467868537452568579\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1474322685454864385\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\hinduphobia\\\\1475397374956564480\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1429321225608728576\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430061294275629062\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430473995804037124\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430522081704296459\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430707575603924992\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430737249390383104\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430743559930404864\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430764998083571712\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430884839536750595\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430928842747781126\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\historical_hindu_muslim\\\\1430934427471810560\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1426975893583396869\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1427127023047114756\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1427132613525852161\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1427164007366942722\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1427169794726400005\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1443896879461244936\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1448906155850453018\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1457070488669376518\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1457771384143167500\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1457992274353160192\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1460363642252189705\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1460517156630663169\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1460523326384709637\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1464461678704308233\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1467510184142524421\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1479780170265288706\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1486934002816540685\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1530852232484204544\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1533393257215840256\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1533414078798254080\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1533742495426674688\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1533820267339866113\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1534043530368552960\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1534125155236073474\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\islamophobia\\\\1534698276540542976\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\jew\\\\1484674130184130564\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\jew\\\\1487696043815104515\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\kashmir\\\\1432282015903199235\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\kashmir\\\\1465844898280579077\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\kashmir\\\\1465910508024832006\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\namaz_on_public_space\\\\1443581212514152451\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\namaz_on_public_space\\\\1443581537908187145\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\namaz_on_public_space\\\\1458858336443518984\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\namaz_on_public_space\\\\1459864236423725056\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\namaz_on_public_space\\\\1468076489992065026\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\russia_ukarain_conflict\\\\1497403265750867971\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\russia_ukarain_conflict\\\\1497404257443753986\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\taliban\\\\1426951286243561482\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\taliban\\\\1426954684464435203\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\taliban\\\\1426966700927315972\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\taliban\\\\1427091167569715202\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\taliban\\\\1427156888639217665\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\taliban\\\\1427164365753446400\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1335539265015517186\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1431810085500694530\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1432187242567458818\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1465305031003893763\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1465319335849771012\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1465339797640151044\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467526803606540292\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467549830499078145\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467672078975258625\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467687038140907522\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467689036991008770\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467697523447848964\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467702790948474880\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467706058613288963\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467712410534309889\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467713383612829697\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467728527202021377\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467746096134852611\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1467746524394262533\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1468894517654740994\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1470064763950362629\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1470338865227460613\\\\',\n",
       " 'testdata/train\\\\Hinglish\\\\temple_mosque_controversies\\\\1470356920556929025\\\\']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in train_directories:\n",
    "    try:\n",
    "        with open(i+'data.json', encoding='utf-8') as f:\n",
    "            data.append(json.load(f))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "binary_labels = []\n",
    "for i in train_directories:\n",
    "    if('Hinglish' in i):\n",
    "        with open(i+'binary_labels.json', encoding='utf-8') as f:\n",
    "            binary_labels.append(json.load(f))\n",
    "    else:\n",
    "        try:\n",
    "            with open(i+'labels.json', encoding='utf-8') as f:\n",
    "                binary_labels.append(json.load(f))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_flatten(d,l):\n",
    "    flat_text = []\n",
    "    flat_text.append({\n",
    "        'tweet_id':d['tweet_id'],\n",
    "        'text':d['tweet'],\n",
    "        'label':l[d['tweet_id']]\n",
    "    })\n",
    "\n",
    "    for i in d['comments']:\n",
    "            flat_text.append({\n",
    "                'tweet_id':i['tweet_id'],\n",
    "                'text':flat_text[0]['text'] +' '+i['tweet'], \n",
    "                'label':l[i['tweet_id']]\n",
    "            })\n",
    "            if 'replies' in i.keys():\n",
    "                for j in i['replies']:\n",
    "                    flat_text.append({\n",
    "                        'tweet_id':j['tweet_id'],\n",
    "                        'text':flat_text[0]['text'] +' '+ i['tweet'] +' '+ j['tweet'], \n",
    "                        'label':l[j['tweet_id']]\n",
    "                    })\n",
    "    return flat_text\n",
    "\n",
    "def te_flatten(d):\n",
    "    flat_text = []\n",
    "    flat_text.append({\n",
    "        'tweet_id':d['tweet_id'],\n",
    "        'text':d['tweet'],\n",
    "    })\n",
    "\n",
    "    for i in d['comments']:\n",
    "            flat_text.append({\n",
    "                'tweet_id':i['tweet_id'],\n",
    "                'text':flat_text[0]['text'] + i['tweet'],\n",
    "            })\n",
    "            if 'replies' in i.keys():\n",
    "                for j in i['replies']:\n",
    "                    flat_text.append({\n",
    "                        'tweet_id':j['tweet_id'],\n",
    "                        'text':flat_text[0]['text'] + i['tweet'] + j['tweet'],\n",
    "                    })\n",
    "    return flat_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = []\n",
    "#for train\n",
    "for i in range(len(binary_labels)):\n",
    "    for j in tr_flatten(data[i], binary_labels[i]):\n",
    "        data_label.append(j)\n",
    "train_len = len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_label, columns = data_label[0].keys(), index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1480483303253680129</td>\n",
       "      <td>Ein HNO-#Arzt aus #Weilheim geht juristisch ge...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1480483587866742792</td>\n",
       "      <td>Ein HNO-#Arzt aus #Weilheim geht juristisch ge...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1480483755055845376</td>\n",
       "      <td>Ein HNO-#Arzt aus #Weilheim geht juristisch ge...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1480486718864502787</td>\n",
       "      <td>Ein HNO-#Arzt aus #Weilheim geht juristisch ge...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480484022132301829</td>\n",
       "      <td>Ein HNO-#Arzt aus #Weilheim geht juristisch ge...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1480483303253680129  Ein HNO-#Arzt aus #Weilheim geht juristisch ge...   \n",
       "1  1480483587866742792  Ein HNO-#Arzt aus #Weilheim geht juristisch ge...   \n",
       "2  1480483755055845376  Ein HNO-#Arzt aus #Weilheim geht juristisch ge...   \n",
       "3  1480486718864502787  Ein HNO-#Arzt aus #Weilheim geht juristisch ge...   \n",
       "4  1480484022132301829  Ein HNO-#Arzt aus #Weilheim geht juristisch ge...   \n",
       "\n",
       "  label  \n",
       "0  NONE  \n",
       "1  NONE  \n",
       "2  NONE  \n",
       "3  NONE  \n",
       "4  NONE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOF    2612\n",
       "NOT    2609\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['label'] == 'NONE'] = 'NOT'\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.text\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_english_hindi_emojis=\"[^a-zA-Z#\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF\\u0900-\\u097F]\"\n",
    "def clean_tweet(tweet, english_stemmer, stopword):\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
    "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
    "    tweet = re.sub(regex_for_english_hindi_emojis, ' ', tweet)\n",
    "    tweet = re.sub(\"RT \", \" \", tweet)\n",
    "    tweet = re.sub(\"\\n\", \" \", tweet)\n",
    "    tweet = re.sub(r\" +\", \" \", tweet)\n",
    "    tokens = []\n",
    "    for token in tweet.split():\n",
    "        if token not in stopword:\n",
    "            token = english_stemmer.stem(token)\n",
    "            token = hindi_stemmer.hi_stem(token)\n",
    "            tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = [clean_tweet(\n",
    "        tweet, english_stemmer, stopword) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 5)\n",
    "X = vectorizer.fit_transform(cleaned_tweets)\n",
    "X = X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\New_folder\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\New_folder\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HOF       0.71      0.81      0.75       240\n",
      "         NOT       0.82      0.72      0.76       283\n",
      "\n",
      "    accuracy                           0.76       523\n",
      "   macro avg       0.76      0.76      0.76       523\n",
      "weighted avg       0.77      0.76      0.76       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.compile('adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "147/147 [==============================] - 2s 4ms/step - loss: 0.6072 - accuracy: 0.6709\n",
      "Epoch 2/5\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.4709 - accuracy: 0.7676\n",
      "Epoch 3/5\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8127\n",
      "Epoch 4/5\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8510\n",
      "Epoch 5/5\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2521b80bd90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred = (y_pred > 0.4).astype('int64')\n",
    "y_pred = y_pred.reshape(len(y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76       240\n",
      "           1       0.81      0.75      0.78       283\n",
      "\n",
      "    accuracy                           0.77       523\n",
      "   macro avg       0.77      0.77      0.77       523\n",
      "weighted avg       0.77      0.77      0.77       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directories = []\n",
    "for i in glob(\"testdata/test/*/*/\"):\n",
    "    for j in glob(i+'*/'):\n",
    "        test_directories.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testdata/test\\\\German\\\\Corona\\\\1530498233398607873\\\\',\n",
       " 'testdata/test\\\\German\\\\green party\\\\1534603102179016708\\\\',\n",
       " 'testdata/test\\\\German\\\\Presiden\\\\1486034666968731655\\\\',\n",
       " 'testdata/test\\\\German\\\\Rassismus\\\\1367179784372047876\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\celebrity_controversies\\\\1425321569350414343\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\celebrity_controversies\\\\1438882238087659525\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\farmer_protest\\\\1480518248076509184\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\hinduphobia\\\\1445930336039358469\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\hinduphobia\\\\1467895004223791105\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\hinduphobia\\\\1470652707824291843\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\historical_hindu_muslim\\\\1445435933214617602\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\islamophobia\\\\1442176510224261120\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\islamophobia\\\\1533444368690032641\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\ozil\\\\1438762071835951104\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\russia_ukarain_conflict\\\\1497413697056215043\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\temple_mosque_controversies\\\\1467712410534309889\\\\',\n",
       " 'testdata/test\\\\Hinglish\\\\temple_mosque_controversies\\\\1467731786151170049\\\\']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in test_directories:\n",
    "    with open(i+'data.json', encoding='utf-8') as f:\n",
    "        data.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweetid_data = []\n",
    "#for test\n",
    "for i in range(len(binary_labels), len(data)):\n",
    "    for j in te_flatten(data[i]):\n",
    "        test_tweetid_data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_tweetid_data, columns = test_tweetid_data[0].keys(), index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1530498233398607873</td>\n",
       "      <td>Die Protagonisten der letzten 2 Jahre fordern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530498806164365318</td>\n",
       "      <td>Die Protagonisten der letzten 2 Jahre fordern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1530499829901807621</td>\n",
       "      <td>Die Protagonisten der letzten 2 Jahre fordern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1530507651326611457</td>\n",
       "      <td>Die Protagonisten der letzten 2 Jahre fordern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1530531871037263873</td>\n",
       "      <td>Die Protagonisten der letzten 2 Jahre fordern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text\n",
       "0  1530498233398607873  Die Protagonisten der letzten 2 Jahre fordern ...\n",
       "1  1530498806164365318  Die Protagonisten der letzten 2 Jahre fordern ...\n",
       "2  1530499829901807621  Die Protagonisten der letzten 2 Jahre fordern ...\n",
       "3  1530507651326611457  Die Protagonisten der letzten 2 Jahre fordern ...\n",
       "4  1530531871037263873  Die Protagonisten der letzten 2 Jahre fordern ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = test_df.text\n",
    "tweet_ids = test_df.tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test = [clean_tweet(\n",
    "        tweet, english_stemmer, stopword) for tweet in test_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(cleaned_test)\n",
    "X_test = X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\New_folder\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "submission_prediction = classifier.predict(X_test)\n",
    "submission = {'tweet_id': tweet_ids, 'label':submission_prediction}\n",
    "submission = pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msilib import schema\n",
    "\n",
    "\n",
    "submission.to_json('testdata/submission/submission.json',orient='table',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee5e405c00a222202bf8d60a189470d0f00b606dd07429b5cfe5eb3d178e9826"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
